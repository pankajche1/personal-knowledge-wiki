---
title: "Chapter 21: Intuition vs Formula"
date: 2022-03-11Fri19:33:44
draft: true
---

[2022-03-11 Fri 19:34] 

Paul Meehl was a strange and wonderful character, and one of the most versatile psychologists of the twentieth century. Among the departments in which he had faculty appointments at the University of Minnesota were psychology, law, psychiatry, neurology, and philosophy. He also wrote on religion, political science, and learning in rats. A statistically sophisticated researcher and a fierce critic of empty claims in clinical psychology, Meehl was also a practicing psychoanalyst. He wrote thoughtful essays on the philosophical foundations of psychological research that I almost memorized while I was a graduate student. I never met Meehl, but he was one of my heroes from the time I read his *Clinical vs. Statistical Prediction : A Theoretical Analysis and a Review of the Evidence.*

> **Notes:** A psychologist in twentieth century. Paul Meehl. A strange and wonderful character. And the most versatile psychologists. He was faculty in the University of Minnesota. And he was in department of psychology, law, psychiatry, neurology, philosophy. He wrote on religion, political science, and learning in rats. He was also a practicing psychoanalyst. So he was versatile.

In the slim volume that he later called “my disturbing little book,” Meehl reviewed the results of 20 studies that had analyzed whether clinical predictions based on the subjective impressions of trained professionals were more accurate than statistical predictions made by combining a few scores or ratings according to a rule. In a typical study, trained counselors predicted the grades of freshmen at the end of the school year. The counselors interviewed each student for forty-five minutes. They also had access to high school grades, several aptitude tests, and a four-page personal statement. The statistical algorithm used only a fraction of this information: high school grades and one aptitude test. Nevertheless, the formula was more accurate than 11 of the 14 counselors. Meehl reported generally similar results across a variety of other forecast outcomes, including violations of parole, success in pilot training, and criminal recidivism.

> **Notes:** He did this analysis:

> What is more accurate:

> - clinical predictions based on the subjective impressions of trained professionals 
> - statistical predictions made by combining a few scores or ratings according to a rule.

**Q:** How the above analysis was done?    
**Ans:** It was done in two ways:

1. Trained counselors predicted the grades of students at the end of the school year. They interviewed the students and also saw their grades, aptitude tests etc.
2. A statistical algorithm was made using only high school grades and one aptitude test. Then this formula was used to predict.

**Q:** What was the result of the above?    
**Ans:** The algorithm was more accurate.

Not surprisingly, Meehl’s book provoked shock and disbelief among clinical psychologists, and the controversy it started has engendered a stream of research that is still flowing today, more than fifty years after its publication. The number of studies reporting comparisons of clinical and statistical predictions has increased to roughly two hundred, but the score in the contest between algorithms and humans has not changed. About 60% of the studies have shown significantly better accuracy for the algorithms. The other comparisons scored a draw in accuracy, but a tie is tantamount to a win for the statistical rules, which are normally much less expensive to use than expert judgment. No exception has been convincingly documented.

**Q:** What did the Meehl's book do when he told that formula is more accurate than human prediction?    
**Ans:** It provoked shock and disbelief among clinical psychologists. And it started a research that still continued today.

**Q:** What does the above research say?    
**Ans:** 60% studies say that algorithms are better than human.

**Q:** What are the above human and formula predictions called?    
**Ans:** clinical predictions, statistical predictions

The range of predicted outcomes has expanded to cover medical variables such as the longevity of cancer patients, the length of hospital stays, the diagnosis of cardiac disease, and the susceptibility of babies to sudden infant death syndrome; economic measures such as the prospects of success for new businesses, the evaluation of credit risks by banks, and the future career satisfaction of workers; questions of interest to government agencies, including assessments of the suitability of foster parents, the odds of recidivism among juvenile offenders, and the likelihood of other forms of violent behavior; and miscellaneous outcomes such as the evaluation of scientific presentations, the winners of football games, and the future prices of Bordeaux wine. Each of these domains entails a significant degree of uncertainty and unpredictability. We describe them as “low-validity environments.” In every case, the accuracy of experts was matched or exceeded by a simple algorithm.

**Q:** On what areas the predictions were studied?    
**Ans:** 
- medical variables
    - the longevity of cancer patients
	- the length of hospital stays
	- the diagnosis of cardiac disease
	- the susceptibility of babies to sudden infant death syndrome
- economic measures
    - the prospects of success for new businesses
	- the evaluation of credit risks by banks
	- the future career satisfaction of workers
- questions of interest to government agencies
    - assessments of the suitability of foster parents
	- the odds of recidivism among juvenile offenders
	- the likelihood of other forms of violent behavior
- miscellaneous outcomes
    - the evaluation of scientific presentations
	- the winners of football games
	- the future prices of Bordeaux wine.

As Meehl pointed out with justified pride thirty years after the publication of his book, “There is no controversy in social science which shows such a large body of qualitatively diverse studies coming out so uniformly in the same direction as this one.”

The Princeton economist and wine lover Orley Ashenfelter has offered a compelling demonstration of the power of simple statistics to outdo world-renowned experts. Ashenfelter wanted to predict the future value of fine Bordeaux wines from information available in the year they are made. The question is important because fine wines take years to reach their peak quality, and the prices of mature wines from the same vineyard vary dramatically across different vintages; bottles filled only twelve months apart can differ in value by a factor of 10 or more. An ability to forecast future prices is of substantial value, because investors buy wine, like art, in the anticipation that its value will appreciate.

It is generally agreed that the effect of vintage can be due only to variations in the weather during the grape-growing season. The best wines are produced when the summer is warm and dry, which makes the Bordeaux wine industry a likely beneficiary of global warming. The industry is also helped by wet springs, which increase quantity without much effect on quality. Ashenfelter converted that conventional knowledge into a statistical formula that predicts the price of a wine—for a particular property and at a particular age—by three features of the weather: the average temperature over the summer growing season, the amount of rain at harvest-time, and the total rainfall during the previous winter. His formula provides accurate price forecasts years and even decades into the future. Indeed, his formula forecasts future prices much more accurately than the current prices of young wines do. This new example of a “Meehl pattern” challenges the abilities of the experts whose opinions help shape the early price. It also challenges economic theory, according to which prices should reflect all the available information, including the weather. Ashenfelter’s formula is extremely accurate—the correlation between his predictions and actual prices is above .90.

> **Notes:** The above text says that a formula was made to predict the future value of fine Bordeaux wines. It was based on many parameters (temperature etc). And it was very accurate to predict.

TODO

### Do It Yourself

The message of this chapter is readily applicable to tasks other than making manpower decisions for an army. Implementing interview procedures in the spirit of Meehl and Dawes requires relatively little effort but substantial discipline. Suppose that you need to hire a sales representative for your firm. If you are serious about hiring the best possible person for the job, this is what you should do. First, select a few traits that are prerequisites for success in this position (technical proficiency, engaging personality, reliability, and so on). Don’t overdo it— six dimensions is a good number. The traits you choose should be as independent as possible from each other, and you should feel that you can assess them reliably by asking a few factual questions. Next, make a list of those questions for each trait and think about how you will score it, say on a 1–5 scale. You should have an idea of what you will call “very weak” or “very strong.”

These preparations should take you half an hour or so, a small investment that can make a significant difference in the quality of the people you hire. To avoid halo effects, you must collect the information on one trait at a time, scoring each before you move on to the next one. Do not skip around. To evaluate each candidate, add up the six scores. Because you are in charge of the final decision, you should not do a “close your eyes.” Firmly resolve that you will hire the candidate whose final score is the highest, even if there is another one whom you like better—try to resist your wish to invent broken legs to change the ranking. A vast amount of research offers a promise: you are much more likely to find the best candidate if you use this procedure than if you do what people normally do in such situations, which is to go into the interview unprepared and to make choices by an overall intuitive judgment such as “I looked into his eyes and liked what I saw.”

### Speaking of Judges vs. Formulas

1. “Whenever we can replace human judgment by a formula, we should at least consider it.”
2. “He thinks his judgments are complex and subtle, but a simple combination of scores could probably do better.”
3. “Let’s decide in advance what weight to give to the data we have on the candidates’ past performance. Otherwise we will give too much weight to our impression from the interviews.”

